{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 14 2023 15:44:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Microsoft Corporation\n",
      "GL_RENDERER=D3D12 (Intel(R) UHD Graphics 630)\n",
      "GL_VERSION=4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.10\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Microsoft Corporation\n",
      "Renderer = D3D12 (Intel(R) UHD Graphics 630)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Microsoft Corporation\n",
      "ven = Microsoft Corporation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "import roboverse\n",
    "env = roboverse.make('Widow250DoubleDrawerOpenNeutral-v0', gui=True)\n",
    "env.reset()\n",
    "for _ in range(25):\n",
    "    env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 14 2023 15:44:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Microsoft Corporation\n",
      "GL_RENDERER=D3D12 (Intel(R) UHD Graphics 630)\n",
      "GL_VERSION=4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.10\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Microsoft Corporation\n",
      "Renderer = D3D12 (Intel(R) UHD Graphics 630)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Microsoft Corporation\n",
      "ven = Microsoft Corporation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import roboverse\n",
    "env = roboverse.make('Widow250MultiObjectGraspTrain-v0', gui=True)\n",
    "env.reset()\n",
    "for _ in range(250):\n",
    "    env.step(env.action_space.sample())\n",
    "env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 14 2023 15:44:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Microsoft Corporation\n",
      "GL_RENDERER=D3D12 (Intel(R) UHD Graphics 630)\n",
      "GL_VERSION=4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.10\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Microsoft Corporation\n",
      "Renderer = D3D12 (Intel(R) UHD Graphics 630)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Microsoft Corporation\n",
      "ven = Microsoft Corporation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'dict'>`\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import roboverse\n",
    "env = roboverse.make('Widow250MultiObjectPutInBowlRandomBowlPositionTrain-v0', gui=True)\n",
    "env.reset()\n",
    "for _ in range(250):\n",
    "    env.step(env.action_space.sample())\n",
    "env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/scripted_collect.py -n 100 -t 30 -e Widow250PickPlace-v1 -pl grasp -a grasp_success_target --noise=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/scripted_collect.py -n 100 -t 30 -e Widow250PickPlace-v0 -pl pickplace -a place_success_target --noise=0.1 --gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/scripted_collect.py -n 100 -t 30 -e Widow250PickPlaceMultiObject-v0 -pl pickplace -a place_success_target --noise=0.1 --gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 14 2023 15:44:17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import roboverse\n",
    "from roboverse.policies import policies\n",
    "\n",
    "\n",
    "def collect_data(env, model, num_trajectories=100, num_timesteps=30):\n",
    "    policy_class = policies[\"grasp\"]\n",
    "    policy = policy_class(env)\n",
    "    num_success = 0\n",
    "    num_saved = 0\n",
    "    num_attempts = 0\n",
    "    accept_trajectory_key = \"grasp_success_target\"\n",
    "    noise = 0.1\n",
    "    EPSILON = 0.1\n",
    "\n",
    "    while num_saved < num_trajectories:\n",
    "        num_attempts += 1\n",
    "        num_steps = -1\n",
    "        rewards = []\n",
    "        env.reset()\n",
    "        policy.reset()\n",
    "        for j in range(num_timesteps):\n",
    "            action, agent_info = policy.get_action()\n",
    "\n",
    "            # In case we need to pad actions by 1 for easier realNVP modelling\n",
    "            env_action_dim = env.action_space.shape[0]\n",
    "            if env_action_dim - action.shape[0] == 1:\n",
    "                action = np.append(action, 0)\n",
    "            action += np.random.normal(scale=noise, size=(env_action_dim,))\n",
    "            action = np.clip(action, -1 + EPSILON, 1 - EPSILON)\n",
    "            observation = env.get_observation()\n",
    "            #observation[\"image\"] = np.uint8(observation[\"image\"] * 255.)\n",
    "            next_observation, reward, done, info = env.step(action)\n",
    "            #next_observation = np.uint8(next_observation[\"image\"] * 255.)\n",
    "            rewards.append(reward)\n",
    "            model.replay_buffer.add(observation, next_observation, action, reward, done, [{}])\n",
    "\n",
    "            if info[accept_trajectory_key] and num_steps < 0:\n",
    "                num_steps = j\n",
    "\n",
    "            if done or agent_info['done']:\n",
    "                break\n",
    "\n",
    "        if info[accept_trajectory_key]:\n",
    "            if True:\n",
    "                print(\"num_timesteps: \", num_steps)\n",
    "                #print(traj[\"observations\"])\n",
    "            num_success += 1\n",
    "            num_saved += 1\n",
    "        print(f\"num_trajectories: {num_trajectories} success rate: {num_success/num_attempts} Reward: {sum(rewards)}\")\n",
    "\n",
    "    print(\"success rate: {}\".format(num_success / (num_attempts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'dict'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 1.0 Reward: 0.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 100 success rate: 1.0 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.6666666666666666 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.75 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.8 Reward: 0.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 100 success rate: 0.8333333333333334 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.8571428571428571 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.875 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.8888888888888888 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9090909090909091 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9166666666666666 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9230769230769231 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9285714285714286 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9333333333333333 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9375 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9411764705882353 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9444444444444444 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9473684210526315 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.95 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9523809523809523 Reward: 0.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 100 success rate: 0.9545454545454546 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9565217391304348 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9583333333333334 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.96 Reward: 0.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 100 success rate: 0.9615384615384616 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9629629629629629 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9642857142857143 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9655172413793104 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9666666666666667 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.967741935483871 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.96875 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9696969696969697 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9705882352941176 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9714285714285714 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9722222222222222 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.972972972972973 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.9473684210526315 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.9230769230769231 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.925 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.926829268292683 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9285714285714286 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.9069767441860465 Reward: 0.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 100 success rate: 0.9090909090909091 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9111111111111111 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9130434782608695 Reward: 0.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 100 success rate: 0.9148936170212766 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9166666666666666 Reward: 0.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 100 success rate: 0.9183673469387755 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.92 Reward: 0.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 100 success rate: 0.9215686274509803 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9230769230769231 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9245283018867925 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9259259259259259 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9272727272727272 Reward: 0.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 100 success rate: 0.9285714285714286 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9298245614035088 Reward: 0.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 100 success rate: 0.9310344827586207 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9322033898305084 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9333333333333333 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9344262295081968 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9354838709677419 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9365079365079365 Reward: 0.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 100 success rate: 0.9375 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9384615384615385 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9393939393939394 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9402985074626866 Reward: 0.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 100 success rate: 0.9411764705882353 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9420289855072463 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.9285714285714286 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9295774647887324 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9305555555555556 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9315068493150684 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9324324324324325 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9333333333333333 Reward: 0.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 100 success rate: 0.9342105263157895 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.935064935064935 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9358974358974359 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9367088607594937 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9375 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9382716049382716 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9390243902439024 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9397590361445783 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9404761904761905 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9411764705882353 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9418604651162791 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.9310344827586207 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9318181818181818 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9325842696629213 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9333333333333333 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.9230769230769231 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 100 success rate: 0.9239130434782609 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9247311827956989 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.925531914893617 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.9157894736842105 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.90625 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9072164948453608 Reward: 0.0\n",
      "num_trajectories: 100 success rate: 0.8979591836734694 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.898989898989899 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.900990099009901 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 100 success rate: 0.9019607843137255 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9029126213592233 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9038461538461539 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.9047619047619048 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9056603773584906 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9065420560747663 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9074074074074074 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.908256880733945 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 100 success rate: 0.9090909090909091 Reward: 0.0\n",
      "success rate: 0.9090909090909091\n",
      "start learning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2725ba9ecd4c496eae38435e1729522a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 151      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 1510     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.129    |\n",
      "|    critic_loss     | 0.00174  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1359     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "\n",
    "#env = gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")\n",
    "env = roboverse.make(\"Widow250PickPlace-v1\",\n",
    "                         gui=False,\n",
    "                         transpose_image=False)\n",
    "obs = env.reset()\n",
    "\n",
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = TD3(\"MultiInputPolicy\", env, buffer_size=100000, action_noise=action_noise, verbose=1, learning_starts=0)\n",
    "collect_data(env, model, 100, 30)\n",
    "model.save_replay_buffer(\"data/td3_expert_grasp\")\n",
    "\n",
    "print(\"start learning\")\n",
    "for i in range(3):\n",
    "    model.replay_buffer.reset()\n",
    "    model.load_replay_buffer(\"data/td3_expert_grasp\")\n",
    "    model.learn(total_timesteps=3000, log_interval=10, progress_bar=True)\n",
    "print(\"finish learning\")\n",
    "model.save(\"data/td3\")\n",
    "vec_env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = TD3.load(\"data/td3\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "print(\"start render\")\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roboverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
