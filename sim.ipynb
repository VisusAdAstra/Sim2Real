{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python scripts/scripted_collect.py -n 100 -t 30 -e Widow250PickPlace-v1 -pl grasp -a grasp_success_target --noise=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python scripts/scripted_collect.py -n 100 -t 30 -e Widow250PickPlace-v0 -pl pickplace -a place_success_target --noise=0.1 --gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python scripts/scripted_collect.py -n 100 -t 30 -e Widow250PickPlaceMultiObject-v0 -pl pickplace -a place_success_target --noise=0.1 --gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 14 2023 15:44:17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import roboverse\n",
    "from roboverse.policies import policies\n",
    "\n",
    "\n",
    "def collect_data(env, model, policy, target, num_trajectories=100, num_timesteps=30):\n",
    "    policy_class = policies[policy]\n",
    "    policy = policy_class(env)\n",
    "    num_success = 0\n",
    "    num_saved = 0\n",
    "    num_attempts = 0\n",
    "    accept_trajectory_key = target\n",
    "    noise = 0.1\n",
    "    EPSILON = 0.1\n",
    "\n",
    "    while num_saved < num_trajectories:\n",
    "        num_attempts += 1\n",
    "        num_steps = -1\n",
    "        rewards = []\n",
    "        env.reset()\n",
    "        policy.reset()\n",
    "        for j in range(num_timesteps):\n",
    "            action, agent_info = policy.get_action()\n",
    "\n",
    "            # In case we need to pad actions by 1 for easier realNVP modelling \n",
    "            env_action_dim = env.action_space.shape[0]\n",
    "            #if env_action_dim - action.shape[0] == 1:\n",
    "            #    action = np.append(action, 0)\n",
    "            action += np.random.normal(scale=noise, size=(env_action_dim,))\n",
    "            action = np.clip(action, -1 + EPSILON, 1 - EPSILON)\n",
    "            observation = env.get_observation_stacked() #env.get_observation()\n",
    "            next_observation, reward, done, info = env.step(action)\n",
    "            #if not info[accept_trajectory_key]:\n",
    "            #    reward += 0.99**(num_timesteps-j)/10\n",
    "            rewards.append(reward)\n",
    "            model.replay_buffer.add(observation, next_observation, action, reward, done, [{}])\n",
    "\n",
    "            if info[accept_trajectory_key] and num_steps < 0:\n",
    "                num_steps = j\n",
    "\n",
    "            if info[accept_trajectory_key] and j > 18:\n",
    "                break\n",
    "            if done or agent_info['done']:\n",
    "                break\n",
    "\n",
    "        if info[accept_trajectory_key]:\n",
    "            if True:\n",
    "                print(\"num_timesteps: \", num_steps)\n",
    "                #print(traj[\"observations\"])\n",
    "            num_success += 1\n",
    "            num_saved += 1\n",
    "        print(f\"num_trajectories: {num_saved} success rate: {num_success/num_attempts} Reward: {sum(rewards)}\")\n",
    "\n",
    "    print(\"success rate: {}\".format(num_success / (num_attempts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (4, 48, 48, 3)\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'dict'>`\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_timesteps:  15\n",
      "num_trajectories: 1 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 2 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 3 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 4 success rate: 1.0 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 5 success rate: 1.0 Reward: 3.0\n",
      "num_trajectories: 5 success rate: 0.8333333333333334 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 6 success rate: 0.8571428571428571 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 7 success rate: 0.875 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 8 success rate: 0.8888888888888888 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 9 success rate: 0.9 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 10 success rate: 0.9090909090909091 Reward: 7.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 11 success rate: 0.9166666666666666 Reward: 8.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 12 success rate: 0.9230769230769231 Reward: 7.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 13 success rate: 0.9285714285714286 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 14 success rate: 0.9333333333333333 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 15 success rate: 0.9375 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 16 success rate: 0.9411764705882353 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 17 success rate: 0.9444444444444444 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 18 success rate: 0.9473684210526315 Reward: 6.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 19 success rate: 0.95 Reward: 1.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 20 success rate: 0.9523809523809523 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 21 success rate: 0.9545454545454546 Reward: 3.0\n",
      "num_trajectories: 21 success rate: 0.9130434782608695 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 22 success rate: 0.9166666666666666 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 23 success rate: 0.92 Reward: 4.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 24 success rate: 0.9230769230769231 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 25 success rate: 0.9259259259259259 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 26 success rate: 0.9285714285714286 Reward: 5.0\n",
      "num_trajectories: 26 success rate: 0.896551724137931 Reward: 0.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 27 success rate: 0.9 Reward: 1.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 28 success rate: 0.9032258064516129 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 29 success rate: 0.90625 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 30 success rate: 0.9090909090909091 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 31 success rate: 0.9117647058823529 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 32 success rate: 0.9142857142857143 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 33 success rate: 0.9166666666666666 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 34 success rate: 0.918918918918919 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 35 success rate: 0.9210526315789473 Reward: 1.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 36 success rate: 0.9230769230769231 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 37 success rate: 0.925 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 38 success rate: 0.926829268292683 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 39 success rate: 0.9285714285714286 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 40 success rate: 0.9302325581395349 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 41 success rate: 0.9318181818181818 Reward: 8.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 42 success rate: 0.9333333333333333 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 43 success rate: 0.9347826086956522 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 44 success rate: 0.9361702127659575 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 45 success rate: 0.9375 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 46 success rate: 0.9387755102040817 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 47 success rate: 0.94 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 48 success rate: 0.9411764705882353 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 49 success rate: 0.9423076923076923 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 50 success rate: 0.9433962264150944 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 51 success rate: 0.9444444444444444 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 52 success rate: 0.9454545454545454 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 53 success rate: 0.9464285714285714 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 54 success rate: 0.9473684210526315 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 55 success rate: 0.9482758620689655 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 56 success rate: 0.9491525423728814 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 57 success rate: 0.95 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 58 success rate: 0.9508196721311475 Reward: 5.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 59 success rate: 0.9516129032258065 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 60 success rate: 0.9523809523809523 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 61 success rate: 0.953125 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 62 success rate: 0.9538461538461539 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 63 success rate: 0.9545454545454546 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 64 success rate: 0.9552238805970149 Reward: 8.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 65 success rate: 0.9558823529411765 Reward: 4.0\n",
      "num_trajectories: 65 success rate: 0.9420289855072463 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 66 success rate: 0.9428571428571428 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 67 success rate: 0.9436619718309859 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 68 success rate: 0.9444444444444444 Reward: 4.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 69 success rate: 0.9452054794520548 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 70 success rate: 0.9459459459459459 Reward: 4.0\n",
      "num_trajectories: 70 success rate: 0.9333333333333333 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 71 success rate: 0.9342105263157895 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 72 success rate: 0.935064935064935 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 73 success rate: 0.9358974358974359 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 74 success rate: 0.9367088607594937 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 75 success rate: 0.9375 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 76 success rate: 0.9382716049382716 Reward: 6.0\n",
      "num_trajectories: 76 success rate: 0.926829268292683 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 77 success rate: 0.927710843373494 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 78 success rate: 0.9285714285714286 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 79 success rate: 0.9294117647058824 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 80 success rate: 0.9302325581395349 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 81 success rate: 0.9310344827586207 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 82 success rate: 0.9318181818181818 Reward: 4.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 83 success rate: 0.9325842696629213 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 84 success rate: 0.9333333333333333 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 85 success rate: 0.9340659340659341 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 86 success rate: 0.9347826086956522 Reward: 6.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 87 success rate: 0.9354838709677419 Reward: 1.0\n",
      "num_trajectories: 87 success rate: 0.925531914893617 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 88 success rate: 0.9263157894736842 Reward: 5.0\n",
      "num_trajectories: 88 success rate: 0.9166666666666666 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 89 success rate: 0.9175257731958762 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 90 success rate: 0.9183673469387755 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 91 success rate: 0.9191919191919192 Reward: 6.0\n",
      "num_trajectories: 91 success rate: 0.91 Reward: 0.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 92 success rate: 0.9108910891089109 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 93 success rate: 0.9117647058823529 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 94 success rate: 0.912621359223301 Reward: 3.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 95 success rate: 0.9134615384615384 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 96 success rate: 0.9142857142857143 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 97 success rate: 0.9150943396226415 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 98 success rate: 0.9158878504672897 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 99 success rate: 0.9166666666666666 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 100 success rate: 0.9174311926605505 Reward: 2.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 101 success rate: 0.9181818181818182 Reward: 1.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 102 success rate: 0.918918918918919 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 103 success rate: 0.9196428571428571 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 104 success rate: 0.9203539823008849 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 105 success rate: 0.9210526315789473 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 106 success rate: 0.9217391304347826 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 107 success rate: 0.9224137931034483 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 108 success rate: 0.9230769230769231 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 109 success rate: 0.923728813559322 Reward: 7.0\n",
      "num_trajectories: 109 success rate: 0.9159663865546218 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 110 success rate: 0.9166666666666666 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 111 success rate: 0.9173553719008265 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 112 success rate: 0.9180327868852459 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 113 success rate: 0.9186991869918699 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 114 success rate: 0.9193548387096774 Reward: 4.0\n",
      "num_trajectories: 114 success rate: 0.912 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 115 success rate: 0.9126984126984127 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 116 success rate: 0.9133858267716536 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 117 success rate: 0.9140625 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 118 success rate: 0.9147286821705426 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 119 success rate: 0.9153846153846154 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 120 success rate: 0.916030534351145 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 121 success rate: 0.9166666666666666 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 122 success rate: 0.9172932330827067 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 123 success rate: 0.917910447761194 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 124 success rate: 0.9185185185185185 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 125 success rate: 0.9191176470588235 Reward: 4.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 126 success rate: 0.9197080291970803 Reward: 1.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 127 success rate: 0.9202898550724637 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 128 success rate: 0.920863309352518 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 129 success rate: 0.9214285714285714 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 130 success rate: 0.9219858156028369 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 131 success rate: 0.9225352112676056 Reward: 2.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 132 success rate: 0.9230769230769231 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 133 success rate: 0.9236111111111112 Reward: 4.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 134 success rate: 0.9241379310344827 Reward: 1.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 135 success rate: 0.9246575342465754 Reward: 8.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 136 success rate: 0.9251700680272109 Reward: 4.0\n",
      "num_trajectories: 136 success rate: 0.918918918918919 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 137 success rate: 0.9194630872483222 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 138 success rate: 0.92 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 139 success rate: 0.9205298013245033 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 140 success rate: 0.9210526315789473 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 141 success rate: 0.9215686274509803 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 142 success rate: 0.922077922077922 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 143 success rate: 0.9225806451612903 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 144 success rate: 0.9230769230769231 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 145 success rate: 0.9235668789808917 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 146 success rate: 0.9240506329113924 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 147 success rate: 0.9245283018867925 Reward: 4.0\n",
      "num_trajectories: 147 success rate: 0.91875 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 148 success rate: 0.9192546583850931 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 149 success rate: 0.9197530864197531 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 150 success rate: 0.9202453987730062 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 151 success rate: 0.9207317073170732 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 152 success rate: 0.9212121212121213 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 153 success rate: 0.9216867469879518 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 154 success rate: 0.9221556886227545 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 155 success rate: 0.9226190476190477 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 156 success rate: 0.9230769230769231 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 157 success rate: 0.9235294117647059 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 158 success rate: 0.9239766081871345 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 159 success rate: 0.9244186046511628 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 160 success rate: 0.9248554913294798 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 161 success rate: 0.9252873563218391 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 162 success rate: 0.9257142857142857 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 163 success rate: 0.9261363636363636 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 164 success rate: 0.9265536723163842 Reward: 7.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 165 success rate: 0.9269662921348315 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 166 success rate: 0.9273743016759777 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 167 success rate: 0.9277777777777778 Reward: 3.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 168 success rate: 0.9281767955801105 Reward: 9.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 169 success rate: 0.9285714285714286 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 170 success rate: 0.9289617486338798 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 171 success rate: 0.9293478260869565 Reward: 7.0\n",
      "num_trajectories: 171 success rate: 0.9243243243243243 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 172 success rate: 0.9247311827956989 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 173 success rate: 0.9251336898395722 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 174 success rate: 0.925531914893617 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 175 success rate: 0.9259259259259259 Reward: 1.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 176 success rate: 0.9263157894736842 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 177 success rate: 0.9267015706806283 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 178 success rate: 0.9270833333333334 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 179 success rate: 0.927461139896373 Reward: 5.0\n",
      "num_trajectories: 179 success rate: 0.9226804123711341 Reward: 0.0\n",
      "num_trajectories: 179 success rate: 0.9179487179487179 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 180 success rate: 0.9183673469387755 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 181 success rate: 0.9187817258883249 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 182 success rate: 0.9191919191919192 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 183 success rate: 0.9195979899497487 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 184 success rate: 0.92 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 185 success rate: 0.9203980099502488 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 186 success rate: 0.9207920792079208 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 187 success rate: 0.9211822660098522 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 188 success rate: 0.9215686274509803 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 189 success rate: 0.9219512195121952 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 190 success rate: 0.9223300970873787 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 191 success rate: 0.9227053140096618 Reward: 3.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 192 success rate: 0.9230769230769231 Reward: 1.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 193 success rate: 0.9234449760765551 Reward: 8.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 194 success rate: 0.9238095238095239 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 195 success rate: 0.9241706161137441 Reward: 4.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 196 success rate: 0.9245283018867925 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 197 success rate: 0.9248826291079812 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 198 success rate: 0.9252336448598131 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 199 success rate: 0.9255813953488372 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 200 success rate: 0.9259259259259259 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 201 success rate: 0.9262672811059908 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 202 success rate: 0.926605504587156 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 203 success rate: 0.9269406392694064 Reward: 5.0\n",
      "num_trajectories: 203 success rate: 0.9227272727272727 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 204 success rate: 0.9230769230769231 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 205 success rate: 0.9234234234234234 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 206 success rate: 0.9237668161434978 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 207 success rate: 0.9241071428571429 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 208 success rate: 0.9244444444444444 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 209 success rate: 0.9247787610619469 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 210 success rate: 0.9251101321585903 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 211 success rate: 0.9254385964912281 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 212 success rate: 0.925764192139738 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 213 success rate: 0.9260869565217391 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 214 success rate: 0.9264069264069265 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 215 success rate: 0.9267241379310345 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 216 success rate: 0.927038626609442 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 217 success rate: 0.9273504273504274 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 218 success rate: 0.9276595744680851 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 219 success rate: 0.9279661016949152 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 220 success rate: 0.9282700421940928 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 221 success rate: 0.9285714285714286 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 222 success rate: 0.9288702928870293 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 223 success rate: 0.9291666666666667 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 224 success rate: 0.9294605809128631 Reward: 5.0\n",
      "num_trajectories: 224 success rate: 0.9256198347107438 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 225 success rate: 0.9259259259259259 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 226 success rate: 0.9262295081967213 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 227 success rate: 0.926530612244898 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 228 success rate: 0.926829268292683 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 229 success rate: 0.9271255060728745 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 230 success rate: 0.9274193548387096 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 231 success rate: 0.927710843373494 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 232 success rate: 0.928 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 233 success rate: 0.9282868525896414 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 234 success rate: 0.9285714285714286 Reward: 8.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 235 success rate: 0.9288537549407114 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 236 success rate: 0.9291338582677166 Reward: 3.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 237 success rate: 0.9294117647058824 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 238 success rate: 0.9296875 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 239 success rate: 0.9299610894941635 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 240 success rate: 0.9302325581395349 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 241 success rate: 0.9305019305019305 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 242 success rate: 0.9307692307692308 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 243 success rate: 0.9310344827586207 Reward: 8.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 244 success rate: 0.9312977099236641 Reward: 7.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 245 success rate: 0.9315589353612167 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 246 success rate: 0.9318181818181818 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 247 success rate: 0.9320754716981132 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 248 success rate: 0.9323308270676691 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 249 success rate: 0.9325842696629213 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 250 success rate: 0.9328358208955224 Reward: 7.0\n",
      "num_trajectories: 250 success rate: 0.929368029739777 Reward: 0.0\n",
      "num_trajectories: 250 success rate: 0.9259259259259259 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 251 success rate: 0.9261992619926199 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 252 success rate: 0.9264705882352942 Reward: 7.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 253 success rate: 0.9267399267399268 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 254 success rate: 0.927007299270073 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 255 success rate: 0.9272727272727272 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 256 success rate: 0.927536231884058 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 257 success rate: 0.927797833935018 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 258 success rate: 0.9280575539568345 Reward: 6.0\n",
      "num_trajectories: 258 success rate: 0.9247311827956989 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 259 success rate: 0.925 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 260 success rate: 0.9252669039145908 Reward: 4.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 261 success rate: 0.925531914893617 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 262 success rate: 0.9257950530035336 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 263 success rate: 0.926056338028169 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 264 success rate: 0.9263157894736842 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 265 success rate: 0.9265734265734266 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 266 success rate: 0.926829268292683 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 267 success rate: 0.9270833333333334 Reward: 5.0\n",
      "num_timesteps:  29\n",
      "num_trajectories: 268 success rate: 0.9273356401384083 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 269 success rate: 0.9275862068965517 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 270 success rate: 0.9278350515463918 Reward: 7.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 271 success rate: 0.928082191780822 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 272 success rate: 0.9283276450511946 Reward: 5.0\n",
      "num_timesteps:  27\n",
      "num_trajectories: 273 success rate: 0.9285714285714286 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 274 success rate: 0.9288135593220339 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 275 success rate: 0.9290540540540541 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 276 success rate: 0.9292929292929293 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 277 success rate: 0.9295302013422819 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 278 success rate: 0.9297658862876255 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 279 success rate: 0.93 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 280 success rate: 0.9302325581395349 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 281 success rate: 0.9304635761589404 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 282 success rate: 0.9306930693069307 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 283 success rate: 0.930921052631579 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 284 success rate: 0.9311475409836065 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 285 success rate: 0.9313725490196079 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 286 success rate: 0.9315960912052117 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 287 success rate: 0.9318181818181818 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 288 success rate: 0.9320388349514563 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 289 success rate: 0.932258064516129 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 290 success rate: 0.932475884244373 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 291 success rate: 0.9326923076923077 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 292 success rate: 0.9329073482428115 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 293 success rate: 0.9331210191082803 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 294 success rate: 0.9333333333333333 Reward: 4.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 295 success rate: 0.9335443037974683 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 296 success rate: 0.9337539432176656 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 297 success rate: 0.9339622641509434 Reward: 1.0\n",
      "num_timesteps:  25\n",
      "num_trajectories: 298 success rate: 0.9341692789968652 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 299 success rate: 0.934375 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 300 success rate: 0.9345794392523364 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 301 success rate: 0.9347826086956522 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 302 success rate: 0.934984520123839 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 303 success rate: 0.9351851851851852 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 304 success rate: 0.9353846153846154 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 305 success rate: 0.9355828220858896 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 306 success rate: 0.9357798165137615 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 307 success rate: 0.9359756097560976 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 308 success rate: 0.9361702127659575 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 309 success rate: 0.9363636363636364 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 310 success rate: 0.9365558912386707 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 311 success rate: 0.9367469879518072 Reward: 2.0\n",
      "num_trajectories: 311 success rate: 0.933933933933934 Reward: 0.0\n",
      "num_trajectories: 311 success rate: 0.9311377245508982 Reward: 0.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 312 success rate: 0.9313432835820895 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 313 success rate: 0.9315476190476191 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 314 success rate: 0.9317507418397626 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 315 success rate: 0.9319526627218935 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 316 success rate: 0.9321533923303835 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 317 success rate: 0.9323529411764706 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 318 success rate: 0.9325513196480938 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 319 success rate: 0.9327485380116959 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 320 success rate: 0.9329446064139941 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 321 success rate: 0.9331395348837209 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 322 success rate: 0.9333333333333333 Reward: 7.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 323 success rate: 0.9335260115606936 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 324 success rate: 0.9337175792507204 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 325 success rate: 0.9339080459770115 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 326 success rate: 0.9340974212034384 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 327 success rate: 0.9342857142857143 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 328 success rate: 0.9344729344729344 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 329 success rate: 0.9346590909090909 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 330 success rate: 0.9348441926345609 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 331 success rate: 0.9350282485875706 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 332 success rate: 0.9352112676056338 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 333 success rate: 0.9353932584269663 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 334 success rate: 0.9355742296918768 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 335 success rate: 0.9357541899441341 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 336 success rate: 0.935933147632312 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 337 success rate: 0.9361111111111111 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 338 success rate: 0.9362880886426593 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 339 success rate: 0.93646408839779 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 340 success rate: 0.9366391184573003 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 341 success rate: 0.9368131868131868 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 342 success rate: 0.936986301369863 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 343 success rate: 0.9371584699453552 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 344 success rate: 0.9373297002724795 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 345 success rate: 0.9375 Reward: 5.0\n",
      "num_trajectories: 345 success rate: 0.9349593495934959 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 346 success rate: 0.9351351351351351 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 347 success rate: 0.9353099730458221 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 348 success rate: 0.9354838709677419 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 349 success rate: 0.935656836461126 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 350 success rate: 0.9358288770053476 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 351 success rate: 0.936 Reward: 2.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 352 success rate: 0.9361702127659575 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 353 success rate: 0.9363395225464191 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 354 success rate: 0.9365079365079365 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 355 success rate: 0.9366754617414248 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 356 success rate: 0.9368421052631579 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 357 success rate: 0.937007874015748 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 358 success rate: 0.93717277486911 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 359 success rate: 0.9373368146214099 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 360 success rate: 0.9375 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 361 success rate: 0.9376623376623376 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 362 success rate: 0.9378238341968912 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 363 success rate: 0.937984496124031 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 364 success rate: 0.9381443298969072 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 365 success rate: 0.9383033419023136 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 366 success rate: 0.9384615384615385 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 367 success rate: 0.9386189258312021 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 368 success rate: 0.9387755102040817 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 369 success rate: 0.9389312977099237 Reward: 6.0\n",
      "num_trajectories: 369 success rate: 0.9365482233502538 Reward: 0.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 370 success rate: 0.9367088607594937 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 371 success rate: 0.9368686868686869 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 372 success rate: 0.9370277078085643 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 373 success rate: 0.9371859296482412 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 374 success rate: 0.9373433583959899 Reward: 6.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 375 success rate: 0.9375 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 376 success rate: 0.9376558603491272 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 377 success rate: 0.9378109452736318 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 378 success rate: 0.9379652605459057 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 379 success rate: 0.9381188118811881 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 380 success rate: 0.9382716049382716 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 381 success rate: 0.9384236453201971 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 382 success rate: 0.9385749385749386 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 383 success rate: 0.9387254901960784 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 384 success rate: 0.9388753056234719 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 385 success rate: 0.9390243902439024 Reward: 1.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 386 success rate: 0.9391727493917275 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 387 success rate: 0.9393203883495146 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 388 success rate: 0.9394673123486683 Reward: 4.0\n",
      "num_trajectories: 388 success rate: 0.9371980676328503 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 389 success rate: 0.9373493975903614 Reward: 7.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 390 success rate: 0.9375 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 391 success rate: 0.9376498800959233 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 392 success rate: 0.937799043062201 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 393 success rate: 0.9379474940334129 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 394 success rate: 0.9380952380952381 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 395 success rate: 0.9382422802850356 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 396 success rate: 0.9383886255924171 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 397 success rate: 0.9385342789598109 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 398 success rate: 0.9386792452830188 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 399 success rate: 0.9388235294117647 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 400 success rate: 0.9389671361502347 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 401 success rate: 0.9391100702576113 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 402 success rate: 0.9392523364485982 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 403 success rate: 0.9393939393939394 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 404 success rate: 0.9395348837209302 Reward: 4.0\n",
      "num_trajectories: 404 success rate: 0.9373549883990719 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 405 success rate: 0.9375 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 406 success rate: 0.9376443418013857 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 407 success rate: 0.9377880184331797 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 408 success rate: 0.9379310344827586 Reward: 5.0\n",
      "num_trajectories: 408 success rate: 0.9357798165137615 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 409 success rate: 0.9359267734553776 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 410 success rate: 0.9360730593607306 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 411 success rate: 0.9362186788154897 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 412 success rate: 0.9363636363636364 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 413 success rate: 0.9365079365079365 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 414 success rate: 0.9366515837104072 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 415 success rate: 0.9367945823927766 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 416 success rate: 0.9369369369369369 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 417 success rate: 0.9370786516853933 Reward: 6.0\n",
      "num_trajectories: 417 success rate: 0.9349775784753364 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 418 success rate: 0.9351230425055929 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 419 success rate: 0.9352678571428571 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 420 success rate: 0.9354120267260579 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 421 success rate: 0.9355555555555556 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 422 success rate: 0.9356984478935698 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 423 success rate: 0.9358407079646017 Reward: 3.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 424 success rate: 0.9359823399558499 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 425 success rate: 0.9361233480176211 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 426 success rate: 0.9362637362637363 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 427 success rate: 0.9364035087719298 Reward: 6.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 428 success rate: 0.936542669584245 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 429 success rate: 0.9366812227074236 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 430 success rate: 0.9368191721132898 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 431 success rate: 0.9369565217391305 Reward: 8.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 432 success rate: 0.9370932754880694 Reward: 1.0\n",
      "num_trajectories: 432 success rate: 0.935064935064935 Reward: 0.0\n",
      "num_trajectories: 432 success rate: 0.9330453563714903 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 433 success rate: 0.9331896551724138 Reward: 2.0\n",
      "num_trajectories: 433 success rate: 0.9311827956989247 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 434 success rate: 0.9313304721030042 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 435 success rate: 0.9314775160599572 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 436 success rate: 0.9316239316239316 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 437 success rate: 0.9317697228144989 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 438 success rate: 0.9319148936170213 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 439 success rate: 0.9320594479830149 Reward: 3.0\n",
      "num_trajectories: 439 success rate: 0.9300847457627118 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 440 success rate: 0.9302325581395349 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 441 success rate: 0.930379746835443 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 442 success rate: 0.9305263157894736 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 443 success rate: 0.930672268907563 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 444 success rate: 0.9308176100628931 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 445 success rate: 0.9309623430962343 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 446 success rate: 0.9311064718162839 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 447 success rate: 0.93125 Reward: 7.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 448 success rate: 0.9313929313929314 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 449 success rate: 0.9315352697095436 Reward: 6.0\n",
      "num_trajectories: 449 success rate: 0.9296066252587992 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 450 success rate: 0.9297520661157025 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 451 success rate: 0.9298969072164949 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 452 success rate: 0.9300411522633745 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 453 success rate: 0.9301848049281314 Reward: 2.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 454 success rate: 0.930327868852459 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 455 success rate: 0.9304703476482618 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 456 success rate: 0.9306122448979591 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 457 success rate: 0.9307535641547862 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 458 success rate: 0.9308943089430894 Reward: 4.0\n",
      "num_timesteps:  25\n",
      "num_trajectories: 459 success rate: 0.9310344827586207 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 460 success rate: 0.9311740890688259 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 461 success rate: 0.9313131313131313 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 462 success rate: 0.9314516129032258 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 463 success rate: 0.93158953722334 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 464 success rate: 0.9317269076305221 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 465 success rate: 0.9318637274549099 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 466 success rate: 0.932 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 467 success rate: 0.9321357285429142 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 468 success rate: 0.9322709163346613 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 469 success rate: 0.9324055666003976 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 470 success rate: 0.9325396825396826 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 471 success rate: 0.9326732673267327 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 472 success rate: 0.932806324110672 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 473 success rate: 0.9329388560157791 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 474 success rate: 0.9330708661417323 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 475 success rate: 0.9332023575638507 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 476 success rate: 0.9333333333333333 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 477 success rate: 0.9334637964774951 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 478 success rate: 0.93359375 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 479 success rate: 0.9337231968810916 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 480 success rate: 0.933852140077821 Reward: 5.0\n",
      "num_trajectories: 480 success rate: 0.9320388349514563 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 481 success rate: 0.9321705426356589 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 482 success rate: 0.9323017408123792 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 483 success rate: 0.9324324324324325 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 484 success rate: 0.9325626204238922 Reward: 3.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 485 success rate: 0.9326923076923077 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 486 success rate: 0.9328214971209213 Reward: 6.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 487 success rate: 0.9329501915708812 Reward: 9.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 488 success rate: 0.9330783938814532 Reward: 4.0\n",
      "num_trajectories: 488 success rate: 0.9312977099236641 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 489 success rate: 0.9314285714285714 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 490 success rate: 0.9315589353612167 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 491 success rate: 0.9316888045540797 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 492 success rate: 0.9318181818181818 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 493 success rate: 0.9319470699432892 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 494 success rate: 0.9320754716981132 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 495 success rate: 0.9322033898305084 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 496 success rate: 0.9323308270676691 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 497 success rate: 0.9324577861163227 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 498 success rate: 0.9325842696629213 Reward: 6.0\n",
      "num_trajectories: 498 success rate: 0.930841121495327 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 499 success rate: 0.9309701492537313 Reward: 4.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 500 success rate: 0.931098696461825 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 501 success rate: 0.9312267657992565 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 502 success rate: 0.9313543599257885 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 503 success rate: 0.9314814814814815 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 504 success rate: 0.9316081330868762 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 505 success rate: 0.9317343173431735 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 506 success rate: 0.9318600368324125 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 507 success rate: 0.9319852941176471 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 508 success rate: 0.9321100917431193 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 509 success rate: 0.9322344322344323 Reward: 6.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 510 success rate: 0.9323583180987203 Reward: 9.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 511 success rate: 0.9324817518248175 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 512 success rate: 0.9326047358834244 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 513 success rate: 0.9327272727272727 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 514 success rate: 0.9328493647912885 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 515 success rate: 0.9329710144927537 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 516 success rate: 0.9330922242314648 Reward: 5.0\n",
      "num_timesteps:  27\n",
      "num_trajectories: 517 success rate: 0.9332129963898917 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 518 success rate: 0.9333333333333333 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 519 success rate: 0.9334532374100719 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 520 success rate: 0.933572710951526 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 521 success rate: 0.9336917562724014 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 522 success rate: 0.9338103756708408 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 523 success rate: 0.9339285714285714 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 524 success rate: 0.9340463458110517 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 525 success rate: 0.9341637010676157 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 526 success rate: 0.9342806394316163 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 527 success rate: 0.9343971631205674 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 528 success rate: 0.9345132743362832 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 529 success rate: 0.9346289752650176 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 530 success rate: 0.9347442680776014 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 531 success rate: 0.9348591549295775 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 532 success rate: 0.9349736379613357 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 533 success rate: 0.9350877192982456 Reward: 2.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 534 success rate: 0.9352014010507881 Reward: 1.0\n",
      "num_trajectories: 534 success rate: 0.9335664335664335 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 535 success rate: 0.9336823734729494 Reward: 5.0\n",
      "num_timesteps:  25\n",
      "num_trajectories: 536 success rate: 0.9337979094076655 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 537 success rate: 0.9339130434782609 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 538 success rate: 0.9340277777777778 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 539 success rate: 0.9341421143847487 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 540 success rate: 0.9342560553633218 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 541 success rate: 0.9343696027633851 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 542 success rate: 0.9344827586206896 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 543 success rate: 0.9345955249569707 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 544 success rate: 0.9347079037800687 Reward: 1.0\n",
      "num_trajectories: 544 success rate: 0.9331046312178388 Reward: 0.0\n",
      "num_timesteps:  29\n",
      "num_trajectories: 545 success rate: 0.9332191780821918 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 546 success rate: 0.9333333333333333 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 547 success rate: 0.9334470989761092 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 548 success rate: 0.9335604770017035 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 549 success rate: 0.9336734693877551 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 550 success rate: 0.933786078098472 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 551 success rate: 0.9338983050847458 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 552 success rate: 0.934010152284264 Reward: 3.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 553 success rate: 0.9341216216216216 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 554 success rate: 0.9342327150084317 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 555 success rate: 0.9343434343434344 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 556 success rate: 0.934453781512605 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 557 success rate: 0.9345637583892618 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 558 success rate: 0.9346733668341709 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 559 success rate: 0.9347826086956522 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 560 success rate: 0.9348914858096828 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 561 success rate: 0.935 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 562 success rate: 0.9351081530782029 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 563 success rate: 0.9352159468438538 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 564 success rate: 0.9353233830845771 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 565 success rate: 0.9354304635761589 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 566 success rate: 0.9355371900826446 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 567 success rate: 0.9356435643564357 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 568 success rate: 0.9357495881383855 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 569 success rate: 0.9358552631578947 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 570 success rate: 0.9359605911330049 Reward: 5.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 571 success rate: 0.9360655737704918 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 572 success rate: 0.9361702127659575 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 573 success rate: 0.9362745098039216 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 574 success rate: 0.9363784665579119 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 575 success rate: 0.9364820846905537 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 576 success rate: 0.9365853658536586 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 577 success rate: 0.9366883116883117 Reward: 3.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 578 success rate: 0.9367909238249594 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 579 success rate: 0.9368932038834952 Reward: 5.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 580 success rate: 0.9369951534733441 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 581 success rate: 0.9370967741935484 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 582 success rate: 0.9371980676328503 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 583 success rate: 0.9372990353697749 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 584 success rate: 0.9373996789727127 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 585 success rate: 0.9375 Reward: 4.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 586 success rate: 0.9376 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 587 success rate: 0.9376996805111821 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 588 success rate: 0.937799043062201 Reward: 4.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 589 success rate: 0.9378980891719745 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 590 success rate: 0.9379968203497615 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 591 success rate: 0.9380952380952381 Reward: 7.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 592 success rate: 0.9381933438985737 Reward: 7.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 593 success rate: 0.9382911392405063 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 594 success rate: 0.9383886255924171 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 595 success rate: 0.9384858044164038 Reward: 2.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 596 success rate: 0.9385826771653544 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 597 success rate: 0.9386792452830188 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 598 success rate: 0.9387755102040817 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 599 success rate: 0.9388714733542319 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 600 success rate: 0.9389671361502347 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 601 success rate: 0.9390625 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 602 success rate: 0.9391575663026521 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 603 success rate: 0.9392523364485982 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 604 success rate: 0.9393468118195957 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 605 success rate: 0.9394409937888198 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 606 success rate: 0.9395348837209302 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 607 success rate: 0.9396284829721362 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 608 success rate: 0.9397217928902627 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 609 success rate: 0.9398148148148148 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 610 success rate: 0.9399075500770416 Reward: 2.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 611 success rate: 0.94 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 612 success rate: 0.9400921658986175 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 613 success rate: 0.9401840490797546 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 614 success rate: 0.9402756508422665 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 615 success rate: 0.9403669724770642 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 616 success rate: 0.9404580152671755 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 617 success rate: 0.9405487804878049 Reward: 8.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 618 success rate: 0.9406392694063926 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 619 success rate: 0.9407294832826748 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 620 success rate: 0.9408194233687405 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 621 success rate: 0.9409090909090909 Reward: 4.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 622 success rate: 0.9409984871406959 Reward: 1.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 623 success rate: 0.9410876132930514 Reward: 1.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 624 success rate: 0.9411764705882353 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 625 success rate: 0.9412650602409639 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 626 success rate: 0.9413533834586466 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 627 success rate: 0.9414414414414415 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 628 success rate: 0.9415292353823088 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 629 success rate: 0.9416167664670658 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 630 success rate: 0.9417040358744395 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 631 success rate: 0.9417910447761194 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 632 success rate: 0.9418777943368107 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 633 success rate: 0.9419642857142857 Reward: 3.0\n",
      "num_trajectories: 633 success rate: 0.9405646359583952 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 634 success rate: 0.9406528189910979 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 635 success rate: 0.9407407407407408 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 636 success rate: 0.9408284023668639 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 637 success rate: 0.9409158050221565 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 638 success rate: 0.9410029498525073 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 639 success rate: 0.9410898379970545 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 640 success rate: 0.9411764705882353 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 641 success rate: 0.9412628487518355 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 642 success rate: 0.9413489736070382 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 643 success rate: 0.9414348462664714 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 644 success rate: 0.9415204678362573 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 645 success rate: 0.9416058394160584 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 646 success rate: 0.9416909620991254 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 647 success rate: 0.9417758369723436 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 648 success rate: 0.9418604651162791 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 649 success rate: 0.941944847605225 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 650 success rate: 0.9420289855072463 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 651 success rate: 0.9421128798842258 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 652 success rate: 0.9421965317919075 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 653 success rate: 0.9422799422799423 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 654 success rate: 0.9423631123919308 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 655 success rate: 0.9424460431654677 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 656 success rate: 0.9425287356321839 Reward: 4.0\n",
      "num_trajectories: 656 success rate: 0.9411764705882353 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 657 success rate: 0.9412607449856734 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 658 success rate: 0.9413447782546495 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 659 success rate: 0.9414285714285714 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 660 success rate: 0.9415121255349501 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 661 success rate: 0.9415954415954416 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 662 success rate: 0.9416785206258891 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 663 success rate: 0.9417613636363636 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 664 success rate: 0.9418439716312057 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 665 success rate: 0.9419263456090652 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 666 success rate: 0.942008486562942 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 667 success rate: 0.942090395480226 Reward: 6.0\n",
      "num_trajectories: 667 success rate: 0.9407616361071932 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 668 success rate: 0.9408450704225352 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 669 success rate: 0.9409282700421941 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 670 success rate: 0.9410112359550562 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 671 success rate: 0.94109396914446 Reward: 7.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 672 success rate: 0.9411764705882353 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 673 success rate: 0.9412587412587412 Reward: 2.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 674 success rate: 0.9413407821229051 Reward: 2.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 675 success rate: 0.9414225941422594 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 676 success rate: 0.9415041782729805 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 677 success rate: 0.9415855354659249 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 678 success rate: 0.9416666666666667 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 679 success rate: 0.941747572815534 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 680 success rate: 0.9418282548476454 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 681 success rate: 0.941908713692946 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 682 success rate: 0.9419889502762431 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 683 success rate: 0.9420689655172414 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 684 success rate: 0.9421487603305785 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 685 success rate: 0.9422283356258597 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 686 success rate: 0.9423076923076923 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 687 success rate: 0.9423868312757202 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 688 success rate: 0.9424657534246575 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 689 success rate: 0.9425444596443229 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 690 success rate: 0.9426229508196722 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 691 success rate: 0.9427012278308322 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 692 success rate: 0.9427792915531336 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 693 success rate: 0.9428571428571428 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 694 success rate: 0.9429347826086957 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 695 success rate: 0.9430122116689281 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 696 success rate: 0.943089430894309 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 697 success rate: 0.9431664411366711 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 698 success rate: 0.9432432432432433 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 699 success rate: 0.9433198380566802 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 700 success rate: 0.9433962264150944 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 701 success rate: 0.9434724091520862 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 702 success rate: 0.9435483870967742 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 703 success rate: 0.9436241610738255 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 704 success rate: 0.9436997319034852 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 705 success rate: 0.9437751004016064 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 706 success rate: 0.9438502673796791 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 707 success rate: 0.9439252336448598 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 708 success rate: 0.944 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 709 success rate: 0.9440745672436751 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 710 success rate: 0.9441489361702128 Reward: 3.0\n",
      "num_trajectories: 710 success rate: 0.9428950863213812 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 711 success rate: 0.9429708222811671 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 712 success rate: 0.9430463576158941 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 713 success rate: 0.9431216931216931 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 714 success rate: 0.9431968295904888 Reward: 4.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 715 success rate: 0.9432717678100264 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 716 success rate: 0.9433465085638999 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 717 success rate: 0.9434210526315789 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 718 success rate: 0.9434954007884363 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 719 success rate: 0.9435695538057742 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 720 success rate: 0.9436435124508519 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 721 success rate: 0.943717277486911 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 722 success rate: 0.9437908496732026 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 723 success rate: 0.943864229765013 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 724 success rate: 0.9439374185136897 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 725 success rate: 0.9440104166666666 Reward: 6.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 726 success rate: 0.9440832249674902 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 727 success rate: 0.9441558441558442 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 728 success rate: 0.9442282749675746 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 729 success rate: 0.944300518134715 Reward: 1.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 730 success rate: 0.944372574385511 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 731 success rate: 0.9444444444444444 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 732 success rate: 0.944516129032258 Reward: 4.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 733 success rate: 0.9445876288659794 Reward: 9.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 734 success rate: 0.9446589446589446 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 735 success rate: 0.9447300771208226 Reward: 4.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 736 success rate: 0.944801026957638 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 737 success rate: 0.9448717948717948 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 738 success rate: 0.9449423815620999 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 739 success rate: 0.9450127877237852 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 740 success rate: 0.9450830140485313 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 741 success rate: 0.9451530612244898 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 742 success rate: 0.9452229299363057 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 743 success rate: 0.94529262086514 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 744 success rate: 0.9453621346886912 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 745 success rate: 0.9454314720812182 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 746 success rate: 0.9455006337135615 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 747 success rate: 0.9455696202531646 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 748 success rate: 0.9456384323640961 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 749 success rate: 0.9457070707070707 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 750 success rate: 0.9457755359394704 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 751 success rate: 0.9458438287153652 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 752 success rate: 0.9459119496855346 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 753 success rate: 0.9459798994974874 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 754 success rate: 0.946047678795483 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 755 success rate: 0.9461152882205514 Reward: 2.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 756 success rate: 0.9461827284105131 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 757 success rate: 0.94625 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 758 success rate: 0.9463171036204744 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 759 success rate: 0.9463840399002493 Reward: 5.0\n",
      "num_trajectories: 759 success rate: 0.9452054794520548 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 760 success rate: 0.945273631840796 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 761 success rate: 0.9453416149068323 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 762 success rate: 0.9454094292803971 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 763 success rate: 0.9454770755885997 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 764 success rate: 0.9455445544554455 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 765 success rate: 0.9456118665018541 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 766 success rate: 0.945679012345679 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 767 success rate: 0.9457459926017263 Reward: 7.0\n",
      "num_trajectories: 767 success rate: 0.9445812807881774 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 768 success rate: 0.9446494464944649 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 769 success rate: 0.9447174447174447 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 770 success rate: 0.9447852760736196 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 771 success rate: 0.9448529411764706 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 772 success rate: 0.944920440636475 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 773 success rate: 0.9449877750611247 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 774 success rate: 0.945054945054945 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 775 success rate: 0.9451219512195121 Reward: 5.0\n",
      "num_trajectories: 775 success rate: 0.9439707673568819 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 776 success rate: 0.9440389294403893 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 777 success rate: 0.9441069258809235 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 778 success rate: 0.9441747572815534 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 779 success rate: 0.9442424242424242 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 780 success rate: 0.9443099273607748 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 781 success rate: 0.9443772672309553 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 782 success rate: 0.9444444444444444 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 783 success rate: 0.9445114595898673 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 784 success rate: 0.944578313253012 Reward: 7.0\n",
      "num_trajectories: 784 success rate: 0.9434416365824309 Reward: 0.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 785 success rate: 0.9435096153846154 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 786 success rate: 0.943577430972389 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 787 success rate: 0.9436450839328537 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 788 success rate: 0.9437125748502994 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 789 success rate: 0.94377990430622 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 790 success rate: 0.9438470728793309 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 791 success rate: 0.9439140811455847 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 792 success rate: 0.9439809296781884 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 793 success rate: 0.944047619047619 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 794 success rate: 0.9441141498216409 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 795 success rate: 0.9441805225653207 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 796 success rate: 0.9442467378410438 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 797 success rate: 0.9443127962085308 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 798 success rate: 0.9443786982248521 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 799 success rate: 0.9444444444444444 Reward: 5.0\n",
      "num_trajectories: 799 success rate: 0.9433293978748524 Reward: 0.0\n",
      "num_trajectories: 799 success rate: 0.9422169811320755 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 800 success rate: 0.9422850412249706 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 801 success rate: 0.9423529411764706 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 802 success rate: 0.9424206815511164 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 803 success rate: 0.9424882629107981 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 804 success rate: 0.9425556858147714 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 805 success rate: 0.9426229508196722 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 806 success rate: 0.9426900584795321 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 807 success rate: 0.9427570093457944 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 808 success rate: 0.9428238039673279 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 809 success rate: 0.9428904428904429 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 810 success rate: 0.9429569266589057 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 811 success rate: 0.9430232558139535 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 812 success rate: 0.943089430894309 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 813 success rate: 0.9431554524361949 Reward: 6.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 814 success rate: 0.9432213209733488 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 815 success rate: 0.9432870370370371 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 816 success rate: 0.9433526011560693 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 817 success rate: 0.9434180138568129 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 818 success rate: 0.9434832756632064 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 819 success rate: 0.9435483870967742 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 820 success rate: 0.9436133486766398 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 821 success rate: 0.9436781609195403 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 822 success rate: 0.9437428243398392 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 823 success rate: 0.9438073394495413 Reward: 4.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 824 success rate: 0.9438717067583047 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 825 success rate: 0.9439359267734554 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 826 success rate: 0.944 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 827 success rate: 0.9440639269406392 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 828 success rate: 0.9441277080957811 Reward: 3.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 829 success rate: 0.9441913439635535 Reward: 8.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 830 success rate: 0.944254835039818 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 831 success rate: 0.9443181818181818 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 832 success rate: 0.9443813847900113 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 833 success rate: 0.9444444444444444 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 834 success rate: 0.9445073612684032 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 835 success rate: 0.9445701357466063 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 836 success rate: 0.9446327683615819 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 837 success rate: 0.9446952595936795 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 838 success rate: 0.9447576099210823 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 839 success rate: 0.9448198198198198 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 840 success rate: 0.9448818897637795 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 841 success rate: 0.9449438202247191 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 842 success rate: 0.9450056116722784 Reward: 5.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 843 success rate: 0.945067264573991 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 844 success rate: 0.9451287793952967 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 845 success rate: 0.9451901565995525 Reward: 4.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 846 success rate: 0.9452513966480447 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 847 success rate: 0.9453125 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 848 success rate: 0.9453734671125975 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 849 success rate: 0.9454342984409799 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 850 success rate: 0.9454949944382648 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 851 success rate: 0.9455555555555556 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 852 success rate: 0.9456159822419534 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 853 success rate: 0.9456762749445676 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 854 success rate: 0.9457364341085271 Reward: 1.0\n",
      "num_trajectories: 854 success rate: 0.9446902654867256 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 855 success rate: 0.9447513812154696 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 856 success rate: 0.9448123620309051 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 857 success rate: 0.9448732083792724 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 858 success rate: 0.9449339207048458 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 859 success rate: 0.944994499449945 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 860 success rate: 0.945054945054945 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 861 success rate: 0.9451152579582875 Reward: 7.0\n",
      "num_trajectories: 861 success rate: 0.944078947368421 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 862 success rate: 0.9441401971522454 Reward: 2.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 863 success rate: 0.9442013129102844 Reward: 1.0\n",
      "num_trajectories: 863 success rate: 0.9431693989071038 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 864 success rate: 0.9432314410480349 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 865 success rate: 0.9432933478735005 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 866 success rate: 0.9433551198257081 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 867 success rate: 0.9434167573449401 Reward: 3.0\n",
      "num_trajectories: 867 success rate: 0.9423913043478261 Reward: 0.0\n",
      "num_timesteps:  28\n",
      "num_trajectories: 868 success rate: 0.9424538545059717 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 869 success rate: 0.9425162689804772 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 870 success rate: 0.942578548212351 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 871 success rate: 0.9426406926406926 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 872 success rate: 0.9427027027027027 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 873 success rate: 0.9427645788336934 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 874 success rate: 0.9428263214670982 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 875 success rate: 0.9428879310344828 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 876 success rate: 0.9429494079655544 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 877 success rate: 0.943010752688172 Reward: 1.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 878 success rate: 0.9430719656283566 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 879 success rate: 0.9431330472103004 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 880 success rate: 0.9431939978563773 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 881 success rate: 0.943254817987152 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 882 success rate: 0.9433155080213904 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 883 success rate: 0.9433760683760684 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 884 success rate: 0.9434364994663821 Reward: 8.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 885 success rate: 0.9434968017057569 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 886 success rate: 0.9435569755058573 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 887 success rate: 0.9436170212765957 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 888 success rate: 0.9436769394261424 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 889 success rate: 0.9437367303609342 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 890 success rate: 0.943796394485684 Reward: 6.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 891 success rate: 0.9438559322033898 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 892 success rate: 0.9439153439153439 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 893 success rate: 0.9439746300211417 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 894 success rate: 0.9440337909186906 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 895 success rate: 0.9440928270042194 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 896 success rate: 0.9441517386722866 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 897 success rate: 0.9442105263157895 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 898 success rate: 0.9442691903259727 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 899 success rate: 0.944327731092437 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 900 success rate: 0.944386149003148 Reward: 3.0\n",
      "num_timesteps:  25\n",
      "num_trajectories: 901 success rate: 0.9444444444444444 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 902 success rate: 0.9445026178010472 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 903 success rate: 0.944560669456067 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 904 success rate: 0.9446185997910136 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 905 success rate: 0.9446764091858038 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 906 success rate: 0.9447340980187695 Reward: 6.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 907 success rate: 0.9447916666666667 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 908 success rate: 0.9448491155046826 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 909 success rate: 0.9449064449064449 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 910 success rate: 0.944963655244029 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 911 success rate: 0.9450207468879668 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 912 success rate: 0.9450777202072539 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 913 success rate: 0.9451345755693582 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 914 success rate: 0.9451913133402275 Reward: 7.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 915 success rate: 0.9452479338842975 Reward: 7.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 916 success rate: 0.9453044375644994 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 917 success rate: 0.945360824742268 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 918 success rate: 0.945417095777549 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 919 success rate: 0.9454732510288066 Reward: 2.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 920 success rate: 0.9455292908530318 Reward: 9.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 921 success rate: 0.9455852156057495 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 922 success rate: 0.9456410256410256 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 923 success rate: 0.9456967213114754 Reward: 3.0\n",
      "num_trajectories: 923 success rate: 0.9447287615148413 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 924 success rate: 0.9447852760736196 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 925 success rate: 0.9448416751787538 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 926 success rate: 0.9448979591836735 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 927 success rate: 0.944954128440367 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 928 success rate: 0.945010183299389 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 929 success rate: 0.9450661241098678 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 930 success rate: 0.9451219512195121 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 931 success rate: 0.9451776649746193 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 932 success rate: 0.9452332657200812 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 933 success rate: 0.9452887537993921 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 934 success rate: 0.9453441295546559 Reward: 6.0\n",
      "num_trajectories: 934 success rate: 0.9443882709807887 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 935 success rate: 0.9444444444444444 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 936 success rate: 0.9445005045408678 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 937 success rate: 0.9445564516129032 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 938 success rate: 0.9446122860020141 Reward: 3.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 939 success rate: 0.9446680080482898 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 940 success rate: 0.9447236180904522 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 941 success rate: 0.9447791164658634 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 942 success rate: 0.9448345035105316 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 943 success rate: 0.9448897795591182 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 944 success rate: 0.944944944944945 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 945 success rate: 0.945 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 946 success rate: 0.945054945054945 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 947 success rate: 0.9451097804391217 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 948 success rate: 0.9451645064805583 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 949 success rate: 0.9452191235059761 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 950 success rate: 0.945273631840796 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 951 success rate: 0.9453280318091452 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 952 success rate: 0.945382323733863 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 953 success rate: 0.9454365079365079 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 954 success rate: 0.9454905847373637 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 955 success rate: 0.9455445544554455 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 956 success rate: 0.9455984174085065 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 957 success rate: 0.9456521739130435 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 958 success rate: 0.945705824284304 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 959 success rate: 0.9457593688362919 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 960 success rate: 0.9458128078817734 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 961 success rate: 0.9458661417322834 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 962 success rate: 0.9459193706981318 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 963 success rate: 0.9459724950884086 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 964 success rate: 0.9460255152109912 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 965 success rate: 0.946078431372549 Reward: 5.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 966 success rate: 0.9461312438785504 Reward: 9.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 967 success rate: 0.9461839530332681 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 968 success rate: 0.946236559139785 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 969 success rate: 0.9462890625 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 970 success rate: 0.9463414634146341 Reward: 2.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 971 success rate: 0.9463937621832359 Reward: 2.0\n",
      "num_trajectories: 971 success rate: 0.9454722492697176 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 972 success rate: 0.9455252918287937 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 973 success rate: 0.9455782312925171 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 974 success rate: 0.945631067961165 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 975 success rate: 0.9456838021338506 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 976 success rate: 0.9457364341085271 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 977 success rate: 0.9457889641819942 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 978 success rate: 0.9458413926499033 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 979 success rate: 0.9458937198067633 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 980 success rate: 0.9459459459459459 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 981 success rate: 0.9459980713596914 Reward: 3.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 982 success rate: 0.9460500963391136 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 983 success rate: 0.9461020211742059 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 984 success rate: 0.9461538461538461 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 985 success rate: 0.9462055715658021 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 986 success rate: 0.946257197696737 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 987 success rate: 0.9463087248322147 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 988 success rate: 0.946360153256705 Reward: 2.0\n",
      "num_trajectories: 988 success rate: 0.9454545454545454 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 989 success rate: 0.9455066921606119 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 990 success rate: 0.9455587392550143 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 991 success rate: 0.9456106870229007 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 992 success rate: 0.9456625357483317 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 993 success rate: 0.9457142857142857 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 994 success rate: 0.9457659372026641 Reward: 6.0\n",
      "num_trajectories: 994 success rate: 0.9448669201520913 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 995 success rate: 0.9449192782526116 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 996 success rate: 0.9449715370018975 Reward: 5.0\n",
      "num_trajectories: 996 success rate: 0.9440758293838862 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 997 success rate: 0.9441287878787878 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 998 success rate: 0.9441816461684012 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 999 success rate: 0.944234404536862 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 1000 success rate: 0.9442870632672332 Reward: 6.0\n",
      "success rate: 0.9442870632672332\n",
      "start pre-training from buffer only\n",
      "Logging to data/td3/exp_26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6738bd779a4e4a8fbae2f780adc0df29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning\n",
      "Logging to data/td3/exp_26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3dcc4330064fd9bc4ef4d859173ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 1990     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 50.1     |\n",
      "|    critic_loss     | 26.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11791    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 3980     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 51.9     |\n",
      "|    critic_loss     | 1.95     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13781    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 292      |\n",
      "|    total_timesteps | 5970     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 49       |\n",
      "|    critic_loss     | 4.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15771    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 397      |\n",
      "|    total_timesteps | 7960     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 46       |\n",
      "|    critic_loss     | 4.92     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17761    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 498      |\n",
      "|    total_timesteps | 9950     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 42.8     |\n",
      "|    critic_loss     | 5.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19751    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 605      |\n",
      "|    total_timesteps | 11940    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 39.8     |\n",
      "|    critic_loss     | 5.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21741    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 704      |\n",
      "|    total_timesteps | 13930    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 36.9     |\n",
      "|    critic_loss     | 6        |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 23731    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 807      |\n",
      "|    total_timesteps | 15920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 34.3     |\n",
      "|    critic_loss     | 5.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25721    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 913      |\n",
      "|    total_timesteps | 17910    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 31.8     |\n",
      "|    critic_loss     | 4.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27711    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 1025     |\n",
      "|    total_timesteps | 19900    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 29.4     |\n",
      "|    critic_loss     | 3.85     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29701    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to data/td3/exp_26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307c245068894ec6a2ffd7f5d2ab0e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 110      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 21890    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 27.2     |\n",
      "|    critic_loss     | 4.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31691    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 188      |\n",
      "|    total_timesteps | 23880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 25.1     |\n",
      "|    critic_loss     | 3.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33681    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 130      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 281      |\n",
      "|    total_timesteps | 25870    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 23.1     |\n",
      "|    critic_loss     | 3.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35671    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 377      |\n",
      "|    total_timesteps | 27860    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 21.3     |\n",
      "|    critic_loss     | 1.89     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37661    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 150      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 470      |\n",
      "|    total_timesteps | 29850    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 19.6     |\n",
      "|    critic_loss     | 2.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39651    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 563      |\n",
      "|    total_timesteps | 31840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 18       |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41641    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 170      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 656      |\n",
      "|    total_timesteps | 33830    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 16.5     |\n",
      "|    critic_loss     | 2.16     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43631    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 749      |\n",
      "|    total_timesteps | 35820    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 15.1     |\n",
      "|    critic_loss     | 1.55     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45621    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 190      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 844      |\n",
      "|    total_timesteps | 37810    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 13.9     |\n",
      "|    critic_loss     | 1.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47611    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 21       |\n",
      "|    time_elapsed    | 936      |\n",
      "|    total_timesteps | 39800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 12.7     |\n",
      "|    critic_loss     | 1.55     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 49601    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to data/td3/exp_26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43af718bec784accbf02d15788c70335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 210      |\n",
      "|    fps             | 22       |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 41790    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 11.7     |\n",
      "|    critic_loss     | 1.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51591    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 22       |\n",
      "|    time_elapsed    | 160      |\n",
      "|    total_timesteps | 43780    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 10.8     |\n",
      "|    critic_loss     | 0.959    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53581    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 230      |\n",
      "|    fps             | 22       |\n",
      "|    time_elapsed    | 252      |\n",
      "|    total_timesteps | 45770    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 9.92     |\n",
      "|    critic_loss     | 0.896    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 55571    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 21       |\n",
      "|    time_elapsed    | 344      |\n",
      "|    total_timesteps | 47760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 9.16     |\n",
      "|    critic_loss     | 0.762    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 57561    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 250      |\n",
      "|    fps             | 21       |\n",
      "|    time_elapsed    | 435      |\n",
      "|    total_timesteps | 49750    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.5      |\n",
      "|    critic_loss     | 0.632    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 59551    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "\n",
    "env = roboverse.make(\"Widow250PickPlace-v1\",\n",
    "                         gui=False,\n",
    "                         transpose_image=False)\n",
    "obs = env.reset()\n",
    "\n",
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# optimize_memory_usage=True,\n",
    "model = TD3(\"MultiInputPolicy\", env, buffer_size=50000, action_noise=action_noise, learning_rate=0.001, \\\n",
    "            tensorboard_log=\"data/td3\", verbose=1, learning_starts=0) #noise Required for deterministic policy\n",
    "\n",
    "collect_data(env, model, \"grasp\", \"grasp_success_target\", 1000, 30)\n",
    "model.save_replay_buffer(f\"data/td3_expert_grasp\")\n",
    "\n",
    "print(\"start pre-training from buffer only\")\n",
    "model.learn(total_timesteps=0, log_interval=5, tb_log_name=\"exp\", progress_bar=True)\n",
    "model.train(gradient_steps=10000)\n",
    "\n",
    "print(\"start learning\")\n",
    "for i in range(5):\n",
    "    model.learn(total_timesteps=20000, log_interval=10, tb_log_name=\"exp\", reset_num_timesteps = False, progress_bar=True)\n",
    "    model.save(\"data/td3_1\")\n",
    "    #model.replay_buffer.reset()\n",
    "    #model.load_replay_buffer(f\"data/td3_expert_grasp\")\n",
    "\n",
    "print(\"finish learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Microsoft Corporation\n",
      "GL_RENDERER=D3D12 (Intel(R) UHD Graphics 630)\n",
      "GL_VERSION=4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.10\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Microsoft Corporation\n",
      "Renderer = D3D12 (Intel(R) UHD Graphics 630)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Microsoft Corporation\n",
      "ven = Microsoft Corporation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (4, 48, 48, 3)\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'dict'>`\u001b[0m\n",
      "  logger.warn(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_timesteps:  19\n",
      "num_trajectories: 1 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 2 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 3 success rate: 1.0 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 4 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 5 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 6 success rate: 1.0 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 7 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 8 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 9 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 10 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 11 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 12 success rate: 1.0 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 13 success rate: 1.0 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 14 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 15 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 16 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 17 success rate: 1.0 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 18 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 19 success rate: 1.0 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 20 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 21 success rate: 1.0 Reward: 2.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 22 success rate: 1.0 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 23 success rate: 1.0 Reward: 5.0\n",
      "num_trajectories: 23 success rate: 0.9583333333333334 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 24 success rate: 0.96 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 25 success rate: 0.9615384615384616 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 26 success rate: 0.9629629629629629 Reward: 1.0\n",
      "num_trajectories: 26 success rate: 0.9285714285714286 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 27 success rate: 0.9310344827586207 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 28 success rate: 0.9333333333333333 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 29 success rate: 0.9354838709677419 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 30 success rate: 0.9375 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 31 success rate: 0.9393939393939394 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 32 success rate: 0.9411764705882353 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 33 success rate: 0.9428571428571428 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 34 success rate: 0.9444444444444444 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 35 success rate: 0.9459459459459459 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 36 success rate: 0.9473684210526315 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 37 success rate: 0.9487179487179487 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 38 success rate: 0.95 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 39 success rate: 0.9512195121951219 Reward: 4.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 40 success rate: 0.9523809523809523 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 41 success rate: 0.9534883720930233 Reward: 4.0\n",
      "num_trajectories: 41 success rate: 0.9318181818181818 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 42 success rate: 0.9333333333333333 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 43 success rate: 0.9347826086956522 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 44 success rate: 0.9361702127659575 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 45 success rate: 0.9375 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 46 success rate: 0.9387755102040817 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 47 success rate: 0.94 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 48 success rate: 0.9411764705882353 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 49 success rate: 0.9423076923076923 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 50 success rate: 0.9433962264150944 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 51 success rate: 0.9444444444444444 Reward: 1.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 52 success rate: 0.9454545454545454 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 53 success rate: 0.9464285714285714 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 54 success rate: 0.9473684210526315 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 55 success rate: 0.9482758620689655 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 56 success rate: 0.9491525423728814 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 57 success rate: 0.95 Reward: 3.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 58 success rate: 0.9508196721311475 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 59 success rate: 0.9516129032258065 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 60 success rate: 0.9523809523809523 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 61 success rate: 0.953125 Reward: 5.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 62 success rate: 0.9538461538461539 Reward: 1.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 63 success rate: 0.9545454545454546 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 64 success rate: 0.9552238805970149 Reward: 6.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 65 success rate: 0.9558823529411765 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 66 success rate: 0.9565217391304348 Reward: 7.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 67 success rate: 0.9571428571428572 Reward: 1.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 68 success rate: 0.9577464788732394 Reward: 8.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 69 success rate: 0.9583333333333334 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 70 success rate: 0.958904109589041 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 71 success rate: 0.9594594594594594 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 72 success rate: 0.96 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 73 success rate: 0.9605263157894737 Reward: 7.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 74 success rate: 0.961038961038961 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 75 success rate: 0.9615384615384616 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 76 success rate: 0.9620253164556962 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 77 success rate: 0.9625 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 78 success rate: 0.9629629629629629 Reward: 6.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 79 success rate: 0.9634146341463414 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 80 success rate: 0.963855421686747 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 81 success rate: 0.9642857142857143 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 82 success rate: 0.9647058823529412 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 83 success rate: 0.9651162790697675 Reward: 4.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 84 success rate: 0.9655172413793104 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 85 success rate: 0.9659090909090909 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 86 success rate: 0.9662921348314607 Reward: 5.0\n",
      "num_trajectories: 86 success rate: 0.9555555555555556 Reward: 0.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 87 success rate: 0.9560439560439561 Reward: 2.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 88 success rate: 0.9565217391304348 Reward: 1.0\n",
      "num_timesteps:  27\n",
      "num_trajectories: 89 success rate: 0.956989247311828 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 90 success rate: 0.9574468085106383 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 91 success rate: 0.9578947368421052 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 92 success rate: 0.9583333333333334 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 93 success rate: 0.9587628865979382 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 94 success rate: 0.9591836734693877 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 95 success rate: 0.9595959595959596 Reward: 5.0\n",
      "num_trajectories: 95 success rate: 0.95 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 96 success rate: 0.9504950495049505 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 97 success rate: 0.9509803921568627 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 98 success rate: 0.9514563106796117 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 99 success rate: 0.9519230769230769 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 100 success rate: 0.9523809523809523 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 101 success rate: 0.9528301886792453 Reward: 6.0\n",
      "num_trajectories: 101 success rate: 0.9439252336448598 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 102 success rate: 0.9444444444444444 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 103 success rate: 0.944954128440367 Reward: 1.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 104 success rate: 0.9454545454545454 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 105 success rate: 0.9459459459459459 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 106 success rate: 0.9464285714285714 Reward: 8.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 107 success rate: 0.9469026548672567 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 108 success rate: 0.9473684210526315 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 109 success rate: 0.9478260869565217 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 110 success rate: 0.9482758620689655 Reward: 1.0\n",
      "num_trajectories: 110 success rate: 0.9401709401709402 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 111 success rate: 0.940677966101695 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 112 success rate: 0.9411764705882353 Reward: 7.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 113 success rate: 0.9416666666666667 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 114 success rate: 0.9421487603305785 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 115 success rate: 0.9426229508196722 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 116 success rate: 0.943089430894309 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 117 success rate: 0.9435483870967742 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 118 success rate: 0.944 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 119 success rate: 0.9444444444444444 Reward: 6.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 120 success rate: 0.9448818897637795 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 121 success rate: 0.9453125 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 122 success rate: 0.9457364341085271 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 123 success rate: 0.9461538461538461 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 124 success rate: 0.9465648854961832 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 125 success rate: 0.946969696969697 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 126 success rate: 0.9473684210526315 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 127 success rate: 0.9477611940298507 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 128 success rate: 0.9481481481481482 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 129 success rate: 0.9485294117647058 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 130 success rate: 0.948905109489051 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 131 success rate: 0.9492753623188406 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 132 success rate: 0.9496402877697842 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 133 success rate: 0.95 Reward: 1.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 134 success rate: 0.950354609929078 Reward: 8.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 135 success rate: 0.9507042253521126 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 136 success rate: 0.951048951048951 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 137 success rate: 0.9513888888888888 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 138 success rate: 0.9517241379310345 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 139 success rate: 0.952054794520548 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 140 success rate: 0.9523809523809523 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 141 success rate: 0.9527027027027027 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 142 success rate: 0.9530201342281879 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 143 success rate: 0.9533333333333334 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 144 success rate: 0.9536423841059603 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 145 success rate: 0.9539473684210527 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 146 success rate: 0.954248366013072 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 147 success rate: 0.9545454545454546 Reward: 6.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 148 success rate: 0.9548387096774194 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 149 success rate: 0.9551282051282052 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 150 success rate: 0.9554140127388535 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 151 success rate: 0.9556962025316456 Reward: 5.0\n",
      "num_trajectories: 151 success rate: 0.949685534591195 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 152 success rate: 0.95 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 153 success rate: 0.9503105590062112 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 154 success rate: 0.9506172839506173 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 155 success rate: 0.950920245398773 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 156 success rate: 0.9512195121951219 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 157 success rate: 0.9515151515151515 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 158 success rate: 0.9518072289156626 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 159 success rate: 0.9520958083832335 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 160 success rate: 0.9523809523809523 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 161 success rate: 0.9526627218934911 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 162 success rate: 0.9529411764705882 Reward: 5.0\n",
      "num_trajectories: 162 success rate: 0.9473684210526315 Reward: 0.0\n",
      "num_trajectories: 162 success rate: 0.9418604651162791 Reward: 0.0\n",
      "num_trajectories: 162 success rate: 0.9364161849710982 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 163 success rate: 0.9367816091954023 Reward: 5.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 164 success rate: 0.9371428571428572 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 165 success rate: 0.9375 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 166 success rate: 0.9378531073446328 Reward: 6.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 167 success rate: 0.9382022471910112 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 168 success rate: 0.9385474860335196 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 169 success rate: 0.9388888888888889 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 170 success rate: 0.9392265193370166 Reward: 3.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 171 success rate: 0.9395604395604396 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 172 success rate: 0.9398907103825137 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 173 success rate: 0.9402173913043478 Reward: 4.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 174 success rate: 0.9405405405405406 Reward: 9.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 175 success rate: 0.9408602150537635 Reward: 1.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 176 success rate: 0.9411764705882353 Reward: 1.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 177 success rate: 0.9414893617021277 Reward: 9.0\n",
      "num_trajectories: 177 success rate: 0.9365079365079365 Reward: 0.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 178 success rate: 0.9368421052631579 Reward: 9.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 179 success rate: 0.93717277486911 Reward: 2.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 180 success rate: 0.9375 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 181 success rate: 0.9378238341968912 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 182 success rate: 0.9381443298969072 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 183 success rate: 0.9384615384615385 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 184 success rate: 0.9387755102040817 Reward: 4.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 185 success rate: 0.9390862944162437 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 186 success rate: 0.9393939393939394 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 187 success rate: 0.9396984924623115 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 188 success rate: 0.94 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 189 success rate: 0.9402985074626866 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 190 success rate: 0.9405940594059405 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 191 success rate: 0.9408866995073891 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 192 success rate: 0.9411764705882353 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 193 success rate: 0.9414634146341463 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 194 success rate: 0.941747572815534 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 195 success rate: 0.9420289855072463 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 196 success rate: 0.9423076923076923 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 197 success rate: 0.9425837320574163 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 198 success rate: 0.9428571428571428 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 199 success rate: 0.943127962085308 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 200 success rate: 0.9433962264150944 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 201 success rate: 0.9436619718309859 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 202 success rate: 0.9439252336448598 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 203 success rate: 0.9441860465116279 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 204 success rate: 0.9444444444444444 Reward: 1.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 205 success rate: 0.9447004608294931 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 206 success rate: 0.944954128440367 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 207 success rate: 0.9452054794520548 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 208 success rate: 0.9454545454545454 Reward: 5.0\n",
      "num_trajectories: 208 success rate: 0.9411764705882353 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 209 success rate: 0.9414414414414415 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 210 success rate: 0.9417040358744395 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 211 success rate: 0.9419642857142857 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 212 success rate: 0.9422222222222222 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 213 success rate: 0.9424778761061947 Reward: 3.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 214 success rate: 0.9427312775330396 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 215 success rate: 0.9429824561403509 Reward: 4.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 216 success rate: 0.9432314410480349 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 217 success rate: 0.9434782608695652 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 218 success rate: 0.9437229437229437 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 219 success rate: 0.9439655172413793 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 220 success rate: 0.944206008583691 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 221 success rate: 0.9444444444444444 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 222 success rate: 0.9446808510638298 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 223 success rate: 0.9449152542372882 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 224 success rate: 0.9451476793248945 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 225 success rate: 0.9453781512605042 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 226 success rate: 0.9456066945606695 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 227 success rate: 0.9458333333333333 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 228 success rate: 0.946058091286307 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 229 success rate: 0.9462809917355371 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 230 success rate: 0.9465020576131687 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 231 success rate: 0.9467213114754098 Reward: 4.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 232 success rate: 0.9469387755102041 Reward: 8.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 233 success rate: 0.9471544715447154 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 234 success rate: 0.9473684210526315 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 235 success rate: 0.9475806451612904 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 236 success rate: 0.9477911646586346 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 237 success rate: 0.948 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 238 success rate: 0.9482071713147411 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 239 success rate: 0.9484126984126984 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 240 success rate: 0.9486166007905138 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 241 success rate: 0.9488188976377953 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 242 success rate: 0.9490196078431372 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 243 success rate: 0.94921875 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 244 success rate: 0.9494163424124513 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 245 success rate: 0.9496124031007752 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 246 success rate: 0.9498069498069498 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 247 success rate: 0.95 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 248 success rate: 0.9501915708812261 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 249 success rate: 0.950381679389313 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 250 success rate: 0.9505703422053232 Reward: 3.0\n",
      "success rate: 0.9505703422053232\n",
      "num_timesteps:  13\n",
      "num_trajectories: 1 success rate: 1.0 Reward: 7.0\n",
      "num_timesteps:  25\n",
      "num_trajectories: 2 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 3 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 4 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 5 success rate: 1.0 Reward: 2.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 6 success rate: 1.0 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 7 success rate: 1.0 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 8 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 9 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 10 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 11 success rate: 1.0 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 12 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 13 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 14 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 15 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 16 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 17 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 18 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 19 success rate: 1.0 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 20 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 21 success rate: 1.0 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 22 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  21\n",
      "num_trajectories: 23 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 24 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 25 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 26 success rate: 1.0 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 27 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 28 success rate: 1.0 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 29 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 30 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 31 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 32 success rate: 1.0 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 33 success rate: 1.0 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 34 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 35 success rate: 1.0 Reward: 6.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 36 success rate: 1.0 Reward: 8.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 37 success rate: 1.0 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 38 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 39 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 40 success rate: 1.0 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 41 success rate: 1.0 Reward: 7.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 42 success rate: 1.0 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 43 success rate: 1.0 Reward: 4.0\n",
      "num_trajectories: 43 success rate: 0.9772727272727273 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 44 success rate: 0.9777777777777777 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 45 success rate: 0.9782608695652174 Reward: 2.0\n",
      "num_trajectories: 45 success rate: 0.9574468085106383 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 46 success rate: 0.9583333333333334 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 47 success rate: 0.9591836734693877 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 48 success rate: 0.96 Reward: 6.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 49 success rate: 0.9607843137254902 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 50 success rate: 0.9615384615384616 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 51 success rate: 0.9622641509433962 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 52 success rate: 0.9629629629629629 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 53 success rate: 0.9636363636363636 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 54 success rate: 0.9642857142857143 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 55 success rate: 0.9649122807017544 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 56 success rate: 0.9655172413793104 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 57 success rate: 0.9661016949152542 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 58 success rate: 0.9666666666666667 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 59 success rate: 0.9672131147540983 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 60 success rate: 0.967741935483871 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 61 success rate: 0.9682539682539683 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 62 success rate: 0.96875 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 63 success rate: 0.9692307692307692 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 64 success rate: 0.9696969696969697 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 65 success rate: 0.9701492537313433 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 66 success rate: 0.9705882352941176 Reward: 4.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 67 success rate: 0.9710144927536232 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 68 success rate: 0.9714285714285714 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 69 success rate: 0.971830985915493 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 70 success rate: 0.9722222222222222 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 71 success rate: 0.9726027397260274 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 72 success rate: 0.972972972972973 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 73 success rate: 0.9733333333333334 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 74 success rate: 0.9736842105263158 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 75 success rate: 0.974025974025974 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 76 success rate: 0.9743589743589743 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 77 success rate: 0.9746835443037974 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 78 success rate: 0.975 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 79 success rate: 0.9753086419753086 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 80 success rate: 0.975609756097561 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 81 success rate: 0.9759036144578314 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 82 success rate: 0.9761904761904762 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 83 success rate: 0.9764705882352941 Reward: 7.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 84 success rate: 0.9767441860465116 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 85 success rate: 0.9770114942528736 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 86 success rate: 0.9772727272727273 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 87 success rate: 0.9775280898876404 Reward: 2.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 88 success rate: 0.9777777777777777 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 89 success rate: 0.978021978021978 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 90 success rate: 0.9782608695652174 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 91 success rate: 0.978494623655914 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 92 success rate: 0.9787234042553191 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 93 success rate: 0.9789473684210527 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 94 success rate: 0.9791666666666666 Reward: 6.0\n",
      "num_timesteps:  23\n",
      "num_trajectories: 95 success rate: 0.979381443298969 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 96 success rate: 0.9795918367346939 Reward: 5.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 97 success rate: 0.9797979797979798 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 98 success rate: 0.98 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 99 success rate: 0.9801980198019802 Reward: 4.0\n",
      "num_trajectories: 99 success rate: 0.9705882352941176 Reward: 0.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 100 success rate: 0.970873786407767 Reward: 5.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 101 success rate: 0.9711538461538461 Reward: 1.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 102 success rate: 0.9714285714285714 Reward: 8.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 103 success rate: 0.9716981132075472 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 104 success rate: 0.9719626168224299 Reward: 8.0\n",
      "num_trajectories: 104 success rate: 0.9629629629629629 Reward: 0.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 105 success rate: 0.963302752293578 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 106 success rate: 0.9636363636363636 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 107 success rate: 0.963963963963964 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 108 success rate: 0.9642857142857143 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 109 success rate: 0.9646017699115044 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 110 success rate: 0.9649122807017544 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 111 success rate: 0.9652173913043478 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 112 success rate: 0.9655172413793104 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 113 success rate: 0.9658119658119658 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 114 success rate: 0.9661016949152542 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 115 success rate: 0.9663865546218487 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 116 success rate: 0.9666666666666667 Reward: 7.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 117 success rate: 0.9669421487603306 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 118 success rate: 0.9672131147540983 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 119 success rate: 0.967479674796748 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 120 success rate: 0.967741935483871 Reward: 5.0\n",
      "num_timesteps:  22\n",
      "num_trajectories: 121 success rate: 0.968 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 122 success rate: 0.9682539682539683 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 123 success rate: 0.968503937007874 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 124 success rate: 0.96875 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 125 success rate: 0.9689922480620154 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 126 success rate: 0.9692307692307692 Reward: 3.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 127 success rate: 0.9694656488549618 Reward: 1.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 128 success rate: 0.9696969696969697 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 129 success rate: 0.9699248120300752 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 130 success rate: 0.9701492537313433 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 131 success rate: 0.9703703703703703 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 132 success rate: 0.9705882352941176 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 133 success rate: 0.9708029197080292 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 134 success rate: 0.9710144927536232 Reward: 4.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 135 success rate: 0.9712230215827338 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 136 success rate: 0.9714285714285714 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 137 success rate: 0.9716312056737588 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 138 success rate: 0.971830985915493 Reward: 5.0\n",
      "num_timesteps:  26\n",
      "num_trajectories: 139 success rate: 0.972027972027972 Reward: 1.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 140 success rate: 0.9722222222222222 Reward: 3.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 141 success rate: 0.9724137931034482 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 142 success rate: 0.9726027397260274 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 143 success rate: 0.9727891156462585 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 144 success rate: 0.972972972972973 Reward: 5.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 145 success rate: 0.9731543624161074 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 146 success rate: 0.9733333333333334 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 147 success rate: 0.9735099337748344 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 148 success rate: 0.9736842105263158 Reward: 2.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 149 success rate: 0.9738562091503268 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 150 success rate: 0.974025974025974 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 151 success rate: 0.9741935483870968 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 152 success rate: 0.9743589743589743 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 153 success rate: 0.9745222929936306 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 154 success rate: 0.9746835443037974 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 155 success rate: 0.9748427672955975 Reward: 7.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 156 success rate: 0.975 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 157 success rate: 0.9751552795031055 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 158 success rate: 0.9753086419753086 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 159 success rate: 0.9754601226993865 Reward: 6.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 160 success rate: 0.975609756097561 Reward: 1.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 161 success rate: 0.9757575757575757 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 162 success rate: 0.9759036144578314 Reward: 2.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 163 success rate: 0.9760479041916168 Reward: 7.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 164 success rate: 0.9761904761904762 Reward: 9.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 165 success rate: 0.9763313609467456 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 166 success rate: 0.9764705882352941 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 167 success rate: 0.9766081871345029 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 168 success rate: 0.9767441860465116 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 169 success rate: 0.976878612716763 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 170 success rate: 0.9770114942528736 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 171 success rate: 0.9771428571428571 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 172 success rate: 0.9772727272727273 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 173 success rate: 0.9774011299435028 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 174 success rate: 0.9775280898876404 Reward: 7.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 175 success rate: 0.9776536312849162 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 176 success rate: 0.9777777777777777 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 177 success rate: 0.9779005524861878 Reward: 2.0\n",
      "num_trajectories: 177 success rate: 0.9725274725274725 Reward: 0.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 178 success rate: 0.9726775956284153 Reward: 4.0\n",
      "num_timesteps:  11\n",
      "num_trajectories: 179 success rate: 0.9728260869565217 Reward: 9.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 180 success rate: 0.972972972972973 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 181 success rate: 0.9731182795698925 Reward: 5.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 182 success rate: 0.9732620320855615 Reward: 8.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 183 success rate: 0.973404255319149 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 184 success rate: 0.9735449735449735 Reward: 5.0\n",
      "num_timesteps:  24\n",
      "num_trajectories: 185 success rate: 0.9736842105263158 Reward: 1.0\n",
      "num_timesteps:  29\n",
      "num_trajectories: 186 success rate: 0.9738219895287958 Reward: 1.0\n",
      "num_trajectories: 186 success rate: 0.96875 Reward: 0.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 187 success rate: 0.9689119170984456 Reward: 7.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 188 success rate: 0.9690721649484536 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 189 success rate: 0.9692307692307692 Reward: 4.0\n",
      "num_timesteps:  20\n",
      "num_trajectories: 190 success rate: 0.9693877551020408 Reward: 1.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 191 success rate: 0.9695431472081218 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 192 success rate: 0.9696969696969697 Reward: 5.0\n",
      "num_trajectories: 192 success rate: 0.964824120603015 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 193 success rate: 0.965 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 194 success rate: 0.9651741293532339 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 195 success rate: 0.9653465346534653 Reward: 5.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 196 success rate: 0.9655172413793104 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 197 success rate: 0.9656862745098039 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 198 success rate: 0.9658536585365853 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 199 success rate: 0.9660194174757282 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 200 success rate: 0.966183574879227 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 201 success rate: 0.9663461538461539 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 202 success rate: 0.9665071770334929 Reward: 2.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 203 success rate: 0.9666666666666667 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 204 success rate: 0.966824644549763 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 205 success rate: 0.9669811320754716 Reward: 6.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 206 success rate: 0.9671361502347418 Reward: 3.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 207 success rate: 0.9672897196261683 Reward: 1.0\n",
      "num_timesteps:  12\n",
      "num_trajectories: 208 success rate: 0.9674418604651163 Reward: 8.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 209 success rate: 0.9675925925925926 Reward: 4.0\n",
      "num_trajectories: 209 success rate: 0.9631336405529954 Reward: 0.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 210 success rate: 0.963302752293578 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 211 success rate: 0.9634703196347032 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 212 success rate: 0.9636363636363636 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 213 success rate: 0.9638009049773756 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 214 success rate: 0.963963963963964 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 215 success rate: 0.9641255605381166 Reward: 7.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 216 success rate: 0.9642857142857143 Reward: 3.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 217 success rate: 0.9644444444444444 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 218 success rate: 0.9646017699115044 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 219 success rate: 0.9647577092511013 Reward: 4.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 220 success rate: 0.9649122807017544 Reward: 6.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 221 success rate: 0.9650655021834061 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 222 success rate: 0.9652173913043478 Reward: 6.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 223 success rate: 0.9653679653679653 Reward: 7.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 224 success rate: 0.9655172413793104 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 225 success rate: 0.9656652360515021 Reward: 6.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 226 success rate: 0.9658119658119658 Reward: 6.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 227 success rate: 0.9659574468085106 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 228 success rate: 0.9661016949152542 Reward: 3.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 229 success rate: 0.9662447257383966 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 230 success rate: 0.9663865546218487 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 231 success rate: 0.9665271966527197 Reward: 5.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 232 success rate: 0.9666666666666667 Reward: 3.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 233 success rate: 0.966804979253112 Reward: 6.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 234 success rate: 0.9669421487603306 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 235 success rate: 0.9670781893004116 Reward: 5.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 236 success rate: 0.9672131147540983 Reward: 2.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 237 success rate: 0.9673469387755103 Reward: 4.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 238 success rate: 0.967479674796748 Reward: 4.0\n",
      "num_timesteps:  13\n",
      "num_trajectories: 239 success rate: 0.9676113360323887 Reward: 7.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 240 success rate: 0.967741935483871 Reward: 2.0\n",
      "num_timesteps:  19\n",
      "num_trajectories: 241 success rate: 0.9678714859437751 Reward: 1.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 242 success rate: 0.968 Reward: 4.0\n",
      "num_timesteps:  18\n",
      "num_trajectories: 243 success rate: 0.9681274900398407 Reward: 2.0\n",
      "num_timesteps:  17\n",
      "num_trajectories: 244 success rate: 0.9682539682539683 Reward: 3.0\n",
      "num_timesteps:  16\n",
      "num_trajectories: 245 success rate: 0.9683794466403162 Reward: 4.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 246 success rate: 0.968503937007874 Reward: 5.0\n",
      "num_timesteps:  14\n",
      "num_trajectories: 247 success rate: 0.9686274509803922 Reward: 3.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 248 success rate: 0.96875 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 249 success rate: 0.9688715953307393 Reward: 5.0\n",
      "num_timesteps:  15\n",
      "num_trajectories: 250 success rate: 0.9689922480620154 Reward: 5.0\n",
      "success rate: 0.9689922480620154\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "\n",
    "COLLECT = True\n",
    "#env = gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")\n",
    "env = roboverse.make(\"Widow250PickPlace-v1\",\n",
    "                         gui=True,\n",
    "                         transpose_image=False)\n",
    "obs = env.reset()\n",
    "\n",
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# optimize_memory_usage=True,\n",
    "model = TD3(\"MultiInputPolicy\", env, buffer_size=25000, action_noise=action_noise, learning_rate=0.0001, \\\n",
    "            tensorboard_log=\"data/td3\", verbose=1, learning_starts=0) #noise Required for deterministic policy\n",
    "if COLLECT:\n",
    "    for i in range(2):\n",
    "        collect_data(env, model, \"grasp\", \"grasp_success_target\", 250, 30)\n",
    "        model.save_replay_buffer(f\"data/td3_expert_grasp{i+1}\")\n",
    "\n",
    "if not COLLECT:\n",
    "    print(\"start pre-training from buffer only\")\n",
    "    model.replay_buffer.reset()\n",
    "    for i in range(2):\n",
    "        model.load_replay_buffer(f\"data/td3_expert_grasp{i%2+1}\")\n",
    "    model.learn(total_timesteps=0, log_interval=5, tb_log_name=\"exp\", progress_bar=True)\n",
    "    model.train(gradient_steps=2000)\n",
    "\n",
    "    print(\"start learning\")\n",
    "    for i in range(20):\n",
    "        model.learn(total_timesteps=2005, log_interval=5, tb_log_name=\"exp\", progress_bar=True)\n",
    "        if (i+1)%10 == 0:\n",
    "            model.replay_buffer.reset()\n",
    "            model.load_replay_buffer(f\"data/td3_expert_grasp1\")\n",
    "            model.load_replay_buffer(f\"data/td3_expert_grasp2\")\n",
    "            model.save(\"data/td3_1\")\n",
    "\n",
    "    print(\"finish learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "\n",
    "model = TD3.load(\"data/td3_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Microsoft Corporation\n",
      "GL_RENDERER=D3D12 (Intel(R) UHD Graphics 630)\n",
      "GL_VERSION=4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.10\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.1 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Microsoft Corporation\n",
      "Renderer = D3D12 (Intel(R) UHD Graphics 630)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Microsoft Corporation\n",
      "ven = Microsoft Corporation\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "start render\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enhupgu/miniconda3/envs/roboverse/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:225: UserWarning: You tried to render a VecEnv with mode='human' but the render mode defined when initializing the environment must be 'human' or 'rgb_array', not 'None'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart render\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1e5\u001b[39m)):\n\u001b[0;32m---> 16\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     18\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/roboverse/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:553\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    535\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    539\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/roboverse/lib/python3.8/site-packages/stable_baselines3/common/policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    366\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msquash_output:\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;66;03m# Rescale to proper domain when using squashing\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# del model # remove to demonstrate saving and loading\n",
    "# model = TD3.load(\"data/td3_1\")\n",
    "\n",
    "# start env with gui\n",
    "env.close()\n",
    "env = roboverse.make(\"Widow250PickPlace-v1\",\n",
    "                         gui=True,\n",
    "                         transpose_image=False)\n",
    "obs = env.reset()\n",
    "model.set_env(env)\n",
    "env = model.get_env()\n",
    "\n",
    "obs = env.reset()\n",
    "print(\"start render\")\n",
    "for i in range(int(1e4)):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render(\"human\")\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roboverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
